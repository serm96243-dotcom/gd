{
  "title": "Интеграция данных через Apache Kafka",
  "text": "Была ли статья полезной?\nДа\nНет\nСпасибо за вашу оценку!\nОставляя более подробный отзыв, вы помогаете нам улучшать документацию\nКомментарий к оценке\nКонтактная информация (необязательно)\nВложения\nДобавить файл\nОтменить\nОтправить\nИнтеграция данных через Apache Kafka\nApache Kafka\n— это распределенная система обмена сообщениями между серверными приложениями в режиме реального времени.\nО достоинствах и недостатках использования данного брокера сообщений можно ознакомиться на внешних ресурсах, в данной статье будут рассмотрены настройки для взаимодействия приложения GreenData с очередью сообщений Kafka:\nотправление сообщений\nв очередь сообщений;\nчтение сообщений\nиз очереди сообщений.\nОтправление сообщений\nЧтобы поместить сообщение в\nочередь сообщений\n, потребуется настроить\nETL-процесс\n, состоящий минимум из двух этапов: формирования данных для отправки и непосредственно их размещения в очереди сообщений. Для этого следует выполнить несколько шагов, рассмотренных далее.\nШаг 1.\nСоздать объект ETL-процесса\nи настроить его\nсхему\n.\nШаг 2.\nОпределить настройки источника данных. Например, сформировать данные через\nисточник типа \"Внешняя БД\"\n:\nВ рамках кейса рассматривается простой пример формирования данных: генерирование динамической структуры при помощи параметра \"WSDL/JSON\". При этом при помощи sql-запроса значением ноды msg устанавливается строка \"Hello\".\nШаг 3.\nДля отправления данных в очередь используется этап\n\"Приемник. Очередь сообщений\"\n. При настройке данного этапа обязательно должны быть указаны\nпараметры для подключения к очереди сообщений\n.\nВыбор имеющихся подключений доступен в выпадающем списке, создание нового подключения осуществляется по кнопке\n.\nДля интеграции сообщений посредством очереди типа Apache Kafka в параметре \"Тип очереди\" выбирается значение \"Kafka\", после чего задаются\nнастройки для подключения к очереди\n.\nНастройки подключения к очереди необходимо получить у администратора очереди.\nСогласно составленной\nсхеме ETL-процесса\nна вход приемника передается динамическая структура источника, в рамках рассматриваемой задачи в сообщении будет отправлена строка \"msg\", данные которой сериализуются в формате JSON:\nВ очередь сообщений может быть отправлена преобразованная\nдинамическая структура\nв выбранном способе сериализации тела сообщения.\nВ таком случае параметр \"Элемент динамической структуры со значением тела\" остается пустым, а в правой части параметра \"Структура выходов приемника\" формируется отправляемая динамическая структура.\nШаг 4.\nСохранить примененные настойки и\nзапустить ETL-процесс\n.\nПосле выполнения описанных действий, сообщение будет размещено в подключенной очереди Kafka.\nПроверка отправления сообщения.\nПроверить, отправлено ли сообщение, можно при помощи различных инструментов мониторинга за кластерами Kafka, например, при помощи программы\nOffset Explorer\n. Например, выполняя ряд следующих действий:\nСкачать\n, установить и запустить Offset Explorer;\nДобавить новое соединение, нажав правой кнопки мыши по папке \"Clusters\" и выбрав опцию \"Add New Connection\" в контекстном меню:\nВ открывшемся модальном окне на вкладке \"Properties\" в соответствующих полях указать наименование кластера (локальная настройка) и url адрес сервера, на котором развернута Kafka (хост, указанный\nранее\nпри настройке подключения к очереди сообщений):\nНа вкладке \"Advanced\" в качестве параметра \"Bootstrap servers\" добавляется\nранее\nуказанный хост с указанием порта, после чего по кнопке \"Test\" выполняется проверка соединения:\nПри успешной проверке программа выведет модальное окно с  вопросом о добавлении соединения, следует нажать на кнопку \"Yes\":\nЗапустить настроенный ETL-процесс\nотправления сообщения в очередь.\nВ иерархии добавленного кластера в папке \"Topics\" выбрать наименование очереди, указанной при подключении. Перейти на вкладку \"Data\" и нажать на кнопку\n.\nВ таблице отобразятся сообщения, размещенные в очереди:\nПо умолчанию значения отображаются в байтах, для отображения в виде строки необходимо заменить значение соответствующих параметров на вкладке \"Properties\".\nБолее подробное описание подключения Offset Explorer доступно по\nссылке\n.\nЧтение сообщений\nДля проверки наличия новых сообщений в\nочереди\nApache Kafka потребуется настроить\nслушатель очереди сообщений\n. При появлении нового сообщения в очереди слушатель запустит\nETL-процесс\nобработки извлекаемых данных.\nНастройка процесса чтения сообщений из очереди Apache Kafka осуществляется следующим образом:\nШаг 1.\nВ\nреестре\nтипа объектов \"ETL. Слушатель очереди сообщений\" [ETL_MQ_LISTENER] необходимо создать новый экземпляр и настроить согласно последующим шагам.\nШаг 2.\nЧерез меню действий параметра \"ETL для запуска\"\nсоздать новый ETL-процесс\n, указав наименование  (настроенный ранее ETL-процесс выбирается при помощи выпадающего списка).\nШаг 3.\nЧерез меню действий параметра \"Параметры подключения к очереди сообщений\" создать новое\nподключение к очереди сообщений\n(выбор настроенных ранее подключений осуществляется через выпадающий список).\nВ открывшемся модальном окне для чтения сообщений из очереди типа \"Apache Kafka\" в параметре \"Тип очереди\" выбирается значение \"Kafka\", после чего задаются\nнастройки для подключения к очереди\n.\nВ отличие от настройки параметров подключения к очереди сообщений, для отправления сообщения в очередь в данной ситуации необходимо указать название группы слушателей.\nНастройки подключения к очереди необходимо получить у администратора очереди.\nШаг 4.\nСохранить карточку экземпляра. В параметре \"Структура сообщения\" на одноименной вкладке отобразится структура, которую необходимо скопировать для дальнейших действий.\nШаг 5.\nПерейти к настройке\nсхемы\nсозданного объекта ETL-процесса и добавить этап\nисточника типа \"Внешний сервис\"\n.\nВ рамках задачи дополнительно добавлен этап \"Преобразователь\" для вывода всплывающего уведомления при обработке нового сообщения.\nШаг 6.\nПерейти к настройке\nисточника типа \"Внешний сервис\"\n. Определить формат ответа, как \"JSON\", и вставить в поле \"WSDL/JSON\" скопированную в слушателе очереди сообщений\nструктуру сообщения\n.\nПосле сохранения настроек автоматически будет сгенерирована\nдинамическая структура\n.\nСообщение, полученное из очереди, будет разложено в динамическую структуру согласно заданной структуре сообщения.\nШаг 7.\nНастроить преобразователь, создав трансформатор данных по алгоритму, как показано далее:\nПодробнее про функции, использованные в коде алгоритма.\nНазначение используемых в коде алгоритма функций:\nчтобы уведомление выводилось для конкретного пользователя, используется функция\nexecAs\n;\nдля формирования всплывающего информационного сообщения применяется функция\nsendPopUpMsg\n;\nзначения свойства структуры \"payload\" получено при помощи функции\netlValue\n.\nВ результате данных настроек при обработке нового сообщения для пользователя \"Иванов Алексей\" будет выведено уведомление со значением свойства структуры \"payload\".\nШаг 8.\nПосле того как настроены параметры подключения к очереди сообщений и  ETL для запуска, необходимо вернуться в карточку слушателя сообщений и активировать поле \"Слушатель действует\".\nПосле сохранения изменений приложение GreenData настроено для чтения сообщений из очереди Apache Kafka.\nSASL Аутентификация в Kafka\nКогда Kafka развернута в среде с простым уровнем аутентификации и защиты (SASL), при подключении к очереди потребуется указать логин и пароль, предоставленные администратором очереди, а также выбрать вид механизма SASL из доступных вариантов:\nPLAIN;\nSCRAM-SHA-256;\nSCRAM-SHA-512.\nШифрование\nДля обеспечения безопасности подключения к очереди Kafka при помощи протокола\nSSL\nможет быть настроено шифрование канала.\nШаг 1.\nВ первую очередь необходимо создать хранилище доверенных сертификатов.\nВ созданное хранилище необходимо загрузить jks-файл, содержащий доверенные сертификаты, полученные от администратора очереди, и указать пароль от загруженного хранилища.\nПодключение к брокеру возможно, если его сертификат подписан одним из сертификатов из хранилища.\nШаг 2.\nДалее в настройках SSL указать ранее созданное хранилище доверенных сертификатов.\nШаг 3.\nСозданная настройка SSL выбирается при настройке подключения к Kafka.",
  "source": "https://docs.greendata.ru/platform/ru/kafka-integration.html"
}