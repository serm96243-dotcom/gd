{
  "title": "Решение проблем",
  "text": "Была ли статья полезной?\nДа\nНет\nСпасибо за вашу оценку!\nОставляя более подробный отзыв, вы помогаете нам улучшать документацию\nКомментарий к оценке\nКонтактная информация (необязательно)\nВложения\nДобавить файл\nОтменить\nОтправить\nРешение проблем\n1. Контейнер перезапускается\nСимптомы: приложение не отвечает, а контейнер с ним постоянно перезагружается, в логах ничего нет.\nРешение (для приложения, запущенного на физической/виртуальной машине):\nЗакомментируйте блок\nlogging\nв\ndocker-compose.yml\nlogging:\ndriver:\nnone\nyml\nCopied!\nФайл после редактирования:\nservices:\nlowcode:\n# остальные настройки опущены для читабельности конфига\n#logging:\n#  driver: none\nyml\nCopied!\nУдалите и запустите без демона. В этом режиме запуска на экран будут выводиться логи с ошибкой:\ndocker-compose down\ndocker-compose up\nshell\nCopied!\nСкопируйте ошибки и отправьте нам, см.\n4. Контакты\n.\nПосле того как причина ошибки установлена и найдено решение, выполните:\nРаскомментируйте блок\nlogging\n.\nЗапустите приложение как обычно\ndocker-compose up -d\n.\n2. Could not acquire change log lock\nСимптом: в логе приложения есть подобная ошибка:\nCaused by: liquibase.exception.LockException: Could not acquire change log lock.  Currently locked by gd-6d7988b569-b7rjm (10.12.5.99) since 5/30/20 4:50 AM\nat liquibase.lockservice.StandardLockService.waitForLock(StandardLockService.java:190)\nasciidoc\nCopied!\nили повторяется:\nWaiting for changelog lock....\nasciidoc\nCopied!\nПричина: к базе подключилось другое приложение (или еще подключено) и ставит миграции либо приложение было завершено принудительно.\nЧтобы защититься от параллельной установки одних и тех же миграций, в таблицу\ndatabasechangeloglock\nдобавляется запись.\nНо если приложение, добавившее запись в таблицу, упадет или будет экстренно выключено, то строка в таблице останется и не даст запуститься другим приложениям.\nРешение: принудительно снять блокировку, выполнив команду:\nupdate\ndatabasechangeloglock\nset\nlocked\n=\nfalse\nwhere\nid\n=\n1\n;\nsql\nCopied!\n3. Could not get host name\nТакая ошибка может возникнуть, если на сервере не прописан hostname.\nОшибка в логе выглядит следующим образом:\nCaused by: java.lang.RuntimeException: Could not get host name\nCaused by: java.net.UnknownHostException: YOUR_HOST_NAME: Temporary failure in name resolution\nshell\nCopied!\nДля решения этой ошибки выполните следующие действия:\nДобавьте следующую строку в\n/etc/hosts\n:\n127.0.0.1 YOUR_HOST_NAME\nshell\nCopied!\nПроверьте имя хоста, выполнив команду:\nhostname\nshell\nCopied!\nПерезапустите приложение:\ndocker-compose rm -sf\ndocker-compose up -d\nshell\nCopied!\n4. Не подключается WebSocket\nПри наличии Прокси (Nginx, HAProxy и других) между Клиентом (браузером) и Системой необходимо убедиться, что сделаны соответствующие настройки, позволяющие работать websocket.\nНапример, в Nginx websocket по умолчанию выключен. Отрывок конфигурации, позволяющий включить функционал:\nlocation / {\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection $connection_upgrade;\n}\ntext\nCopied!\n5. Падают ошибки связанные с таймаутом\nПри использовании Прокси может потребоваться увеличить таймауты, пример для Nginx:\nlocation / {\nproxy_connect_timeout 5400;\nproxy_send_timeout 5400;\nproxy_read_timeout 5400;\n}\ntext\nCopied!\n6. Не удается загрузить большие файлы\nРешение:\nПример настройки для Nginx.\nДобавить строку в конфигурационный файл Nginx если ее нет.\nУвеличить значение\nclient_max_body_size\nlocation / {\nclient_max_body_size 100m;\n}\ntext\nCopied!\nПример настройки приложения, которое работает без Nginx.\nНастройка выполняется в конфигурационном файле приложения\napp.yml\n:\nspring:\nservlet:\nmultipart:\nmax-file-size:\n200MB\nmax-request-size:\n200MB\nyaml\nCopied!\n7. Снять дамп потоков/памяти\n#\nнаходим контейнер\ndocker ps\n#\nзаходим в контейнер\ndocker exec -it CONTAINER_ID bash\n#\nнаходим процесс и узнаем его PID\nps -aux #ищем процесс с COMMAND java\n#\nснимаем дамп потоков\njstack PID > thread.txt\n#\nснимаем дамп памяти\njmap -dump:live,format=b,file=heap.dmp PID\n#\nвыходим из контейнера Ctrl+D\n#\nкопируем файлы на хост\ndocker cp CONTAINER_ID:/thread.txt ./\ndocker cp CONTAINER_ID:/heap.dmp ./\nshell\nCopied!\n8. FATAL: unsupported startup parameter: search_path\nСимптом: в логе приложения есть подобная ошибка:\nCaused by: org.postgresql.util.PSQLException: FATAL: unsupported startup parameter: search\n_path\nasciidoc\nCopied!\nПричина: использование схемы, отличной от дефолтной\npublic\n, при подключении\njdbc:postgresql://localhost:6432/database?currentSchema=private\nи подключение через PgBouncer.\nРешение:\nДобавить в конфиг\n.ini\nPgBouncer (\nдетали\n)\nignore_startup_parameters:  search_path\nini\nCopied!\nЕсли PgBouncer использует режим\ntransaction pooling\n, то убедиться, что в строке подключения передан аргумент\nprepareThreshold=0\nini\nCopied!\n9. ERROR: relation \"jobrunr_migrations\" already exists\nСимптом: в логе приложения есть подобная ошибка:\nCaused by: org.postgresql.util.PSQLException: ERROR: relation \"jobrunr\n_migrations\" already exists\nasciidoc\nCopied!\nПричина: при разворачивании дампа допустили ошибки, которые привели к тому, что у пользователя не достаточно прав.\nРешение:\nУдалить старую схему:\nDROP\nSCHEMA\nyour_scheme\nCASCADE\n;\nsql\nCopied!\nПараметр\nCASCADE\nавтоматически удаляет объекты, содержащиеся в этой схеме (таблицы, функции и т. д.), и, в свою очередь, все зависящие от них объекты.\nhttps://postgrespro.ru/docs/postgresql/15/sql-dropschema\nСоздать нового пользователя по инструкции\n1.4. Подготовка базы данных Low-Code\n.\nСоздать новую схему:\nCREATE\nSCHEMA\npublic\nAUTHORIZATION low_code_user;\nsql\nCopied!\nВ данном случае создается схема\npublic\nвладелец которой пользователь\nlow_code_user\n.\nРазвернуть дамп.\nПеред разворачиванием дампа, убедитесь, что дамп подготовлен правильно\n1.6. Подготовка дампа базы\n.\n10. ERROR: relation \"gdversion\" does not exist\nСимптом: в логе приложения есть подобная ошибка:\nCaused by: org.postgresql.util.PSQLException: ERROR: relation \"gdversion\" does not exist\nasciidoc\nCopied!\nПричины и решения:\nОшибка подготовки базы данных/Ошибка при разворачивании дампа/Отсутствие прав у пользователя\nРешение: свернуть дамп заново, подготовить пользователя и базу данных, развернуть дамп\nОшибка в строке подключения\nРешение: убедиться, что строка подключения корректна (\nПодробности\n). Например, одна из ошибок может связана с разделителем параметров (используется знак\n&\n, а не\n?\n):\nОшибка (используется два раза\n?\n):\njdbc:postgresql://localhost:6432/database?currentSchema=private?prepareThreshold=0\nПравильно (один раз\n?\n, а дальше\n&\n):\njdbc:postgresql://localhost:6432/database?currentSchema=private&prepareThreshold=0\nPgbouncer не умеет работать со схемой отличной от\npublic\nнапример схемой\nprivate\n, а приложение явно не устанавливает\nsearch_path\nРешение: Установить дефолтную схему для вашей роли, выполнив запрос:\nALTER\nROLE\nlow_code_user\nIN\nDATABASE\nlow_code_db\nSET\nsearch_path\nTO\nyour_scheme;\nsql\nCopied!\n11. No space left on device\nОшибка означает, что на разделе диска, куда docker пишет свои данные, закончилось свободное место.\nРешение: освободить место на диске, для этого требуется выполнить очистку Docker.\nЕсть 2 варианта решения:\nОчистка неиспользуемых контейнеров, сетей, всех имеющихся образов и тома.\nhttps://docs.docker.com/reference/cli/docker/system/prune/\ndocker system prune --all --volumes\nshell\nCopied!\nПараметры команды:\n-f\nНе запрашивать подтверждение\n--all\nУдаление всех образов\n--volumes\nУдаление анонимных томов\nПерезапуск контейнера с остановкой и удалением томов.\nhttps://docs.docker.com/reference/cli/docker/compose/rm/\ndocker-compose rm -sv\ndocker-compose up -d\nshell\nCopied!\nГде:\ndocker-compose rm -sfv Остановка и удаление контейнера с удалением томов.\nПараметры команды:\n-f\nНе запрашивать подтверждение\n-s\nОстановите контейнеры перед их удалением\n-v\nУдаление анонимных томов\nДополнительно можно настроить\nCron\nдля удаления временных файлов старше 2-е суток,\nпример скрипта:\nfind /tmp -name '*.tmp' -mtime +2 -exec rm {} \\;\nshell\nCopied!\n12. Долгая загрузка страницы\nПри долгой загрузке нужно выполнить:\nПроверку зависших сессий и блокировок в БД, выполнив запрос:\nSELECT\nblocked_locks.pid\nAS\nblocked_pid,\nblocked_activity.usename\nAS\nblocked_user,\nblocking_locks.pid\nAS\nblocking_pid,\nblocking_activity.usename\nAS\nblocking_user,\nblocked_activity.query\nAS\nblocked_statement,\nblocking_activity.query\nAS\ncurrent_statement_in_blocking_process\nFROM\npg_catalog.pg_locks         blocked_locks\nJOIN\npg_catalog.pg_stat_activity blocked_activity\nON\nblocked_activity.pid = blocked_locks.pid\nJOIN\npg_catalog.pg_locks         blocking_locks\nON\nblocking_locks.locktype = blocked_locks.locktype\nAND\nblocking_locks.database\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.database\nAND\nblocking_locks.relation\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.relation\nAND\nblocking_locks.page\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.page\nAND\nblocking_locks.tuple\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.tuple\nAND\nblocking_locks.virtualxid\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.virtualxid\nAND\nblocking_locks.transactionid\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.transactionid\nAND\nblocking_locks.classid\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.classid\nAND\nblocking_locks.objid\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.objid\nAND\nblocking_locks.objsubid\nIS\nNOT\nDISTINCT\nFROM\nblocked_locks.objsubid\nAND\nblocking_locks.pid != blocked_locks.pid\nJOIN\npg_catalog.pg_stat_activity blocking_activity\nON\nblocking_activity.pid = blocking_locks.pid\nWHERE\nNOT\nblocked_locks.granted;\nsql\nCopied!\nОтключить зависшие сессии, выполнив запрос:\nSELECT\npg_terminate_backend(НОМЕР_СЕССИИ);\nsql\nCopied!\nи проверить время загрузки.\nПерезагрузить приложение и проверить время загрузки.\nВыполнить\nvacuum analyze\nи проверить время загрузки.\nУзнать как давно статистика не собиралась и\nнастроить автоматический\nvacuum analyze\n.\nЗапросы PostgreSQL, которые могут пригодиться:\nОтключить сессии длительностью свыше 7-ми часов\nSELECT\npg_terminate_backend(pid)\nFROM\npg_stat_activity\nWHERE\nEXTRACT\n(EPOCH\nFROM\n(\nnow\n() - query_start))::\nint\n>\n60\n*\n60\n*\n7\n;\nsql\nCopied!\nСписок активных запросов\nselect\nnow\n() - query_start\nas\ntime_duration,\ndatname,\npid,\nstate,\nwait_event,\nquery\nfrom\npg_stat_activity\nwhere\nstate !=\n'idle'\norder\nby\n1\ndesc\n;\nsql\nCopied!\n20 самых длительных запросов\nSELECT\ndatname,\nsubstring\n(\nquery\n,\n1\n,\n50\n)\nAS\nshort_query,\nround\n(total_time::\nnumeric\n,\n2\n)\nAS\ntotal_time,\ncalls,\nround\n(mean_time::\nnumeric\n,\n2\n)\nAS\nmean,\nround\n((\n100\n* total_time /\nsum\n(total_time::\nnumeric\n)\nOVER\n())::\nnumeric\n,\n2\n)\nAS\npercentage_cpu\nFROM\npg_stat_statements\nJOIN\npg_database\nON\npg_stat_statements.dbid=pg_database.oid\nORDER\nBY\ntotal_time\nDESC\nLIMIT\n20\n;\nsql\nCopied!\n13. Отключение redis при возникновении проблем с кэшем\nПри возникновении проблем с кэшем redis можно временно отключить связь с redis до устранения причин, закоментировав следующие строки в конфигурационном файле app.yml:\ngreendata-core:\n#\nhttp:\n#\nsessionStorage:\n#\ntype\n: REDIS\n#\nredis:\n#\naddress: redis://localhost:6379\n#\ncache:\n#\nremote:\n#\ntype\n: REDIS\n#\nredis:\n#\naddress: redis://localhost:6379\nshell\nCopied!\n14. Зависание приложения\nПри зависании приложения нужно:\nПроверить блокировки в БД и удалить зависшие сессии (см.\nинструкцию\n).\n15. Не работает блокировка доменных учетных данных\nЕсли не работает блокировка доменных учетных данных\nпри отсутствии группы доступа в директории, то нужно добавить\nв конфигурационный файл\napp.yml\nнастройку\ncheckCommonGroupsOnLogon: true\n, пример:\nldap:\nauth:\nenabled:\ntrue\nproviders:\n-\nurls:\n-\nldap://PDC.LOWCODE.LOCAL:389\ndomainName:\nLOWCODE.LOCAL\nloadUserDataOnLogon:\ntrue\ncheckCommonGroupsOnLogon:\ntrue\nyaml\nCopied!\n16. WARN Nginx\n16.1 Client request body is buffered to a temporary file\nПредупреждение означает, что размер загруженного файла превышает размер буфера в памяти, отведенного для загрузки.\nРегулируется настройкой\nclient_body_buffer_size\n.\nДанные о настройке:\nСинтаксис:\n`client_body_buffer_size размер;`\nУмолчание:\n`client_body_buffer_size 8k|16k;`\nКонтекст:\n`http, server,location`\nasciidoc\nCopied!\nНастройка задаёт размер буфера для чтения тела запроса клиента.\nЕсли тело запроса больше заданного буфера, то всё тело запроса или только его часть записывается во временный файл.\nБолее подробную информацию можно узнать тут:\nhttps://nginx.org/ru/docs/http/ngx_http_core_module.html#client_body_buffer_size\n16.2 An upstream response is buffered to a temporary file\nПредупреждение говорит о том, что буферы nginx в оперативной памяти RAM переполнены\nи nginx начинает сохранять тело ответа во временный файл на диск.\nРегулируется настройкой\nproxy_max_temp_file_size\n.\nДанные о настройке:\nСинтаксис:\t proxy\n_max_\ntemp\n_file_\nsize размер;\nУмолчание:         proxy\n_max_\ntemp\n_file_\nsize 1024m;\nКонтекст:\t  http, server, location\nasciidoc\nCopied!\nЕсли включена буферизация ответов проксируемого сервера, и ответ не вмещается целиком в буферы,\nзаданные директивами proxy_buffer_size и proxy_buffers, часть ответа может быть записана во временный файл.\nНастройка\nproxy_temp_file_write_size\nзадаёт максимальный размер временного файла.\nБолее подробную информацию можно узнать тут:\nhttps://nginx.org/ru/docs/http/ngx_http_proxy_module.html#proxy_max_temp_file_size\n16.3 Рекомендации\n1- Увеличить размер буфера с помощью параметра\nclient_body_buffer_size\n.\n2- Отключить буферизацию для загрузки файлов с помощью параметра\nproxy_request_buffering off\n17. Apparent connection leak detected\nДанное сообщение в логе говорит о том, что какое-то из подключений долгое время не возвращается в пул свободных подключений.\nЕсть запросы приложения, которые регулируются параметром\nspring.datasource.hikari.leakDetectionThreshold\n,\nи могут выполняться больше 30 секунд.\nПараметр\nleakDetectionThreshold\nнаходится в файле app.yml:\nspring:\ndatasource:\nhikari:\nleakDetectionThreshold:\n30000\nyaml\nCopied!\nДля анализа ситуации потребуются следующие данные:\nЛоги приложения\nСписок блокировок в БД\nPWR отчет\n18. Сбор данных для анализа проблем с приложением\n18.1. Общие данные для анализа проблем\nОписание проблемы\nУказать время возникновения проблемы с часовым поясом\nКонфигурационные файлы приложения docker-compose.yml и app.yml\nЕсли приложение запущено из war файла, то приложите файлы\napp.yml\nи\napp.conf\nЛог приложения\napp.log\nДамп потоков и памяти по\nинструкции\nЕсли приложение запущено из war файла, дамп потоков и памяти снимаются так:\n#\nнаходим процесс и узнаем его PID\nps -aux | grep java\nлибо\nps -aux | grep java | grep -vi grep | awk '{print $2};' (вывод идентификатора PID без аргументов java)\n#\nСнять дамп потоков\njstack PID > thread.txt\n#\nСнять дамп памяти\njmap -dump:live,format=b,file=heap.dmp PID\nshell\nCopied!\nPWR отчет (Postgres Workload Reporting) с сервера СУБД\nГрафики нагрузки на сервера приложения и базы данных\n18.2. Сбор данных для анализа проблем\nДеградация ноды приложения по CPU и RAM\nПодготовить:\nописание проблемы\nконфигурационные файлы приложения docker-compose.yml либо app.conf и app.yml\nдампы потоков и памяти\nграфик нагрузки на сервере приложения по CPU и RAM\nлог приложения за 15 минут до и 15 минут после возникновения проблемы\nточное время возникновения проблемы с указанием часового пояса, используемого сервером\nДеградация ноды СУБД по CPU и RAM\nПодготовить:\nописание проблемы\nзапрос вызвавший большую нагрузку\nлог приложения за 15 минут до и 15 минут после возникновения проблемы\nграфик нагрузки на сервер СУБД\nесли есть PWR отчет, приложить\nточное время возникновения проблемы с указанием часового пояса, используемого сервером\nУтилизация дискового пространства на сервере приложения при развертывании из docker\nПодготовить:\nописание проблемы\nметрики мониторинга очередь записи\nметрики мониторинга очередь чтения\nметрики мониторинга нагрузка на жесткий диск\nлог приложения за 15 минут до и 15 минут после возникновения проблемы\nточное время возникновения проблемы с указанием часового пояса, используемого сервером\nТрассировки БП и трассировки сигнал/ожидание выполняются с задержкой, либо остановились\nПодготовить:\nописание проблемы\nлог приложения за 15 минут до и 15 минут после возникновения проблемы\nвывод запроса\nselect\n*\nfrom\nwf_trace_event\nwhere\ninstance_id = :instance_id\n#или\nselect\n*\nfrom\nwf_trace_event\nwhere\nobj_id = :obj_id\nsql\nCopied!\nточное время возникновения проблемы с указанием часового пояса, используемого сервером\nОшибки джобранера\nПодготовить:\nописание проблемы\nлог приложения за 15 минут до и 15 минут после возникновения проблемы\nрезультаты запросов\nselect\n*\nfrom\njobrunr_backgroundjobservers jb ;\nselect\n*\nfrom\njobrunr_metadata jm;\nsql\nCopied!\nДалее нужно узнать uuid зависшего задания с помощью запроса\nselect\n*\nfrom\njobrunr_recurring_jobs\nwhere\njobasjson\nlike\n'%836825%'\nsql\nCopied!\nГде\n'%836825%'\nэто\nid\nвашего зависшего задания,\nuuid\nбудет такого вида\n5a54f307-b101-4fbf-8fcb-ee42dc088267\nПодставить uuid в следующий запрос и приложить вывод,\nлибо\nвыгрузить всю таблицу\njobrunr_jobs\n.\nselect\n*\nfrom\njobrunr_jobs jj\nwhere\nrecurringjobid\nin\n(\n'ПОДСТАВЛЕННЫЙ_UUID'\n)\nand\ncreatedat >= TO_TIMESTAMP(\n'УКАЗАТЬ_ПРИМЕРНОЕ_ВРЕМЯ_ПРОБЛЕМЫ'\n,\n'yyyy-mm-dd HH24:MI'\n)\nAND\ncreatedat <= TO_TIMESTAMP(\n'УКАЗАТЬ_ПРИМЕРНОЕ_ВРЕМЯ_ПРОБЛЕМЫ'\n,\n'yyyy-mm-dd HH24:MI'\n)\nsql\nCopied!\nВремя проблемы указывается в формате\n'2024-03-04 12:57'\nточное время возникновения проблемы с указанием часового пояса, используемого сервером\nЗависание маршрутов\nПодготовить:\nописание проблемы\nлог приложения за 15 минут до и 15 минут после возникновения проблемы\nрезультаты запроса\nselect\n*\nfrom\nJOBRUNR_JOBS\nwhere\nid\nin\n(\nselect\nid\nfrom\nsch_job_result\nwhere\nident\nlike\n(\n'WfIntermediateTimer_214033746_233964230%'\n)\nunion\nselect\nid\nfrom\nsch_job_metadata\nwhere\nident\nlike\n(\n'WfIntermediateTimer_214033746_233964230%'\n)\n)\norder\nby\nCREATEDAT\ndesc\nsql\nCopied!\nточное время возникновения проблемы с указанием часового пояса, используемого сервером\nДолгая загрузка страницы\nПодготовить:\nописание проблемы\nHAR-файл, если был подготовлен на момент замедления загрузки\nЗапись HAR-файла\n1. Перейти на страницу, загрузка которой происходит медленно.\n2. Открыть \"Инструменты разработчика\" нажатием клавиши\nF12\nили сочетания клавиш\nCtrl + Shift + I\n, либо открыть пункт меню браузера\nДополнительные инструменты\n→\nИнструменты разработчика\n.\nИнструкция по формированию HAR-файла приведена на примере браузера Google Chrome. Наименования пунктов меню, а также внешний вид кнопок в других браузерах могут отличаться.\n3. Перейти на вкладку \"Сеть\" (\"Network\").\n4. Убедиться, что ведется запись сетевого журнала: в левом верхнем углу кнопка красная\n.\nЕсли запись не ведется (кнопка черная\n), необходимо включить запись нажатием на кнопку.\n5. Включить опцию \"Сохранять журнал\" (\"Preserve log\"):\n6. Чтобы в HAR-файле оказались только записи, касающиеся данной проблемы, необходимо очистить журнал нажатием на кнопку\nсправа от кнопки записи сетевого журнала.\n7. Обновить страницу браузера и повторить действия, которые привели к проблеме.\n8. Экспортировать HAR-файл с помощью кнопки\nили нажав правой кнопкой мыши на таблицу и выбрав в контекстном меню пункт \"Сохранить все как HAR с контентом\" (\"Save all as HAR with content\").\nлог приложения за 15 минут до и 15 минут после возникновения проблемы,\nлоги должны быть уровня DEBUG, чтобы видеть http- и sql-запросы.\nДля логирования http- и sql-запросов на уровне INFO необходимо добавить\nсоответствующие параметры\nв конфигурационный файл.\nдампы потоков и памяти\nPWR отчет\nграфики утилизации ресурсов серверов приложения и СУБД\nсписок активных подключений, которые можно узнать, выполнив следующий запрос в базу\nselect\n*\nfrom\npg_stat_activity;\nsql\nCopied!\nЗависание приложения\nПодготовить:\nописание проблемы\nлоги приложения за 30 минут до и 15 минут после возникновения проблемы\nконфигурационные файлы приложения docker-compose.yml либо app.conf и app.yml\nдампы потоков и памяти\nграфик нагрузки на сервере приложения по CPU и RAM\nточное время возникновения проблемы с указанием часового пояса, используемого сервером\n19. Extension pg_trgm is not avaliable\nОшибка\nExtension pg_trgm is not avaliable\nговорит о том, что в бд не установлено\nрасширение pg_trgm, подробное описание тут\nНеобходимые расширения СУБД PostgreSQL\n.\nРешение:\nУстановить расширения pg_trgm, выполнив запрос в бд приложения:\nCREATE\nEXTENSION\nIF\nNOT\nEXISTS\npg_trgm;\nsql\nCopied!\n20. Too many open files\nВыполнить\nУвеличение количества открываемых файлов в Linux\n21. ERROR: permission denied for schema\nОшибка при выдаче прав в БД. Необходимо корректно раздать права.\n22. Статус контейнера unhealthy\nЕсли вы видите статус контейнера\nunhealthy\n, но при этом приложение функционирует корректно,\nто какие-либо ограничения со стороны приложения отсутствуют и оно будет функционировать со статусом\nunhealthy\n.\n23. ERROR:\nidle_in_transaction_session_timeout\nЭта ошибка возникает, когда транзакция остаётся открытой без активности дольше, чем разрешено настройками PostgreSQL.\nТипичные причины:\nмедленные операции внутри транзакции (например, HTTP-запросы, работа с файлами,\nThread.sleep\n);\nотсутствие\ncommit\nили\nrollback\nпри ручной работе с\nConnection\n;\nблокирующие вызовы в методах с\n@Transactional\nили при использовании\nJdbcTemplate\n.\nДиагностика\nДля детального анализа работы транзакций и JDBC-операций необходимо обновить файл\nlogback.xml\n, добавив, к примеру, следующие настройки:\n<\nlogger\nname\n=\n\"org.springframework.transaction\"\nlevel\n=\n\"DEBUG\"\n/>\n<\nlogger\nname\n=\n\"org.springframework.transaction.interceptor\"\nlevel\n=\n\"DEBUG\"\n/>\n<\nlogger\nname\n=\n\"org.springframework.jdbc.core\"\nlevel\n=\n\"DEBUG\"\n/>\n<\nlogger\nname\n=\n\"org.springframework.jdbc.datasource\"\nlevel\n=\n\"DEBUG\"\n/>\nxml\nCopied!\nЭти настройки позволят:\nотслеживать начало и завершение транзакций (в том числе автоматически создаваемых);\nвидеть вызовы методов с\n@Transactional\n;\nлогировать SQL-запросы и параметры, передаваемые через\nJdbcTemplate\n;\nвыявлять задержки и «зависания» в рамках одной транзакции.\nКлючевые фразы для поиска в логах\nОбращайте внимание на следующие сообщения:\nClosing transaction for\nRolling back JDBC transaction\nTransactionTimedOutException\nIdle-in-transaction timeout expired\nConnection is closed\nЭти строки помогут обнаружить момент прерывания и причину сбоя.\nНастройка таймаута ожидания\nЕсли необходимо изменить лимит ожидания PostgreSQL для неактивных транзакций, задайте параметр:\ngreendata-core:\npostgres:\nsession-parameters:\nidle_in_transaction_session_timeout:\n60min\nyaml\nCopied!\nПо умолчанию используется\n30min\n.\nЗначение применяется к каждому соединению через\nSET\nв\nconnectionInitSql\n.\n24. ObjectNotFoundException: Could not find object with id 108886\nПри откате версии\n4.463.0\nвозможно появление ошибки:\nlowcode.core.exceptions.ObjectNotFoundException: Could not find object with id 108886\nat pro.greendata.core.service.impl.SysSecSubjectServiceImpl.lambda$concatWithAllUsers$7(SysSecSubjectServiceImpl.java:293)\nat java.base/java.util.Optional.orElseThrow(Optional.java:403)\nasciidoc\nCopied!\nВ этом случае можно временно вернуть удаленную группу запросами:\nINSERT\nINTO\nsys_object (\nid\n,\nname\n, type_id, org_id,\nstatus\n, create_date, user_id, name__en, name__ru, created_emp_id, last_modified_user_id, last_modified_emp_id, last_modified_date, is_system, name__fr)\nVALUES\n(\n108886\n,\n'Системный пользователь'\n,\n108665\n,\n100009\n,\n0\n,\n'2016-01-13 10:44:52.746000'\n,\n800\n,\n'System user'\n,\n'Системный пользователь'\n,\n100764\n,\n800\n,\n100764\n,\n'2023-01-30 18:28:14.753000'\n,\n1\n,\n'Utilisateur système'\n);\nINSERT\nINTO\nsys_sec_subject (\nid\n, name__en, name__ru,\nname\n, create_date, type_id,\nstatus\n, org_id, user_id, ident,\nord\n, created_emp_id, last_modified_user_id, last_modified_emp_id, last_modified_date, is_system, name__fr, sys_mass_entity)\nVALUES\n(\n108886\n,\n'System user'\n,\n'Системный пользователь'\n,\n'Системный пользователь'\n,\n'2016-01-13 10:44:52.746000'\n,\n108665\n,\n0\n,\n100009\n,\n800\n,\n'ALL_USERS'\n,\n108886\n,\n100764\n,\n800\n,\n100764\n,\n'2023-01-30 18:28:14.753000'\n,\n1\n,\n'Utilisateur système'\n,\n0\n);\nINSERT\nINTO\nsys_sec_group (\nid\n, name__en, name__ru,\nname\n, create_date, type_id,\nstatus\n, org_id, user_id, ident,\nord\n, created_emp_id, last_modified_user_id, last_modified_emp_id, last_modified_date, is_system, aiy_is_structural, name__fr, sys_mass_entity)\nVALUES\n(\n108886\n,\n'System user'\n,\n'Системный пользователь'\n,\n'Системный пользователь'\n,\n'2016-01-13 10:44:52.746000'\n,\n108665\n,\n0\n,\n100009\n,\n800\n,\n'ALL_USERS'\n,\n108886\n,\n100764\n,\n800\n,\n100764\n,\n'2023-01-30 18:28:14.753000'\n,\n1\n,\nnull\n,\n'Utilisateur système'\n,\n0\n);\nsql\nCopied!\nНо перед повторным обновлением на версию\n4.463.0\nи старше необходимо снова удалить группу:\ndelete\nfrom\nsys_sec_group\nwhere\nid\n=\n108886\n;\ndelete\nfrom\nsys_sec_subject\nwhere\nid\n=\n108886\n;\ndelete\nfrom\nsys_object\nwhere\nid\n=\n108886\n;\nsql\nCopied!\n25. Caused by: java.sql.SQLException: Connection is closed\nОшибка сигнализирует о том, что связь приложения с базой данных разорвана.\nОшибка может быть как сетевой, так и напрямую связанной с работой СУБД.\nНеобходимо восстановить подключение приложения к базе данных.\n26. Отключение записи логов на диск в k8s\nДля того чтобы отключить запись логов на диск в поде k8s, нужно предопределить logback.xml в конфиге deployment.\nПример:\nspec:\ncontainers:\n-\nenv:\n-\nname:\nJAVA_OPTS\nvalue:\n>-\n- ...\n-Dlogging.config=classpath:logback-k8s.xml\nyml\nCopied!\nНачиная с 15-й версии helm-chart, эта настройка установлена по дефолту.\n27. Длительное выполнение SQL-запроса\nВыполнить план медленного запроса. Отследить неоптимальные методы его выполнения.",
  "source": "https://docs.greendata.ru/platform/ru/problem_solving.html"
}